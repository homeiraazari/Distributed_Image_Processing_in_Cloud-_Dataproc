# Distributed_Image_Processing_in_Cloud_Dataproc
In this hands-on lab, I learnt how to use Apache Spark on Cloud Dataproc to distribute a computationally intensive image processing task onto a cluster of machines. This lab is part of a series of labs on processing scientific data.

What you'll learn
Create a managed Cloud Dataproc cluster with Apache Spark pre-installed.
Build and run jobs that use external packages that aren't already installed on the cluster.
Shut down the cluster.
